{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (@ We Rate Dogs) Data Wrangling Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Efforts\n",
    "\n",
    "There are three data sources which i used to gather the required data sets, as the following:\n",
    "\n",
    "- Twitter archive data set about @WeRateDogs Twitter account in **CSV** format\n",
    "    - Contains the basic tweet information like ID, Type, Date, Text, Images, and enhanced with dog stage\n",
    "    - This data set was provided and available offline \n",
    "    - This data was imported and load through default pandas function for CSV files reading \n",
    "    - The data was imported into a separate dataframe\n",
    "- Image Predication data set for the above account's tweets in **TSV** format\n",
    "    - Contains the breed type of the detected dog image through ML modeling\n",
    "    - This data set is downloading programprogrammatically mtically through REQUEST lib from online source\n",
    "    - Also, i kept offline version from it if there any exception during the online reading process\n",
    "    - The data was imported into a separate dataframe\n",
    "- Tweet Counts data set for the above archive in **JSON** format\n",
    "    - I used twitter APIs to search for the tweets in hand and get extra metadata for it like retweet and likw counts\n",
    "    - i used tweepy package to query these APIs and save the results in json file\n",
    "    - json file is parsed for the required fields\n",
    "    - The needed data was imported into a separate dataframe\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Efforts\n",
    "\n",
    "### Visual Assessing\n",
    "- **Twitter Archive** \n",
    "    - There are 'None' values not NaN/False\n",
    "    - Dogs are named with 'a' or 'an'\n",
    "    - There are tweets which are not original tweets and are retweets or replies\n",
    "    - There are rating numerator has value < 10 and rating denominator has value != 10\n",
    "    - There are useless/not important columns that be removed\n",
    "    - Rates extracted correctly from tweet text, and there some outliers values\n",
    "- **Image Predication** \n",
    "    - Nothing as a quality issue\n",
    "    - Ps, Ps_conf and ps_dog can be merged in one/two column as a tidiness issue\n",
    "- **Tweets Count**\n",
    "    - Nothing\n",
    "    \n",
    "### Code Assessing\n",
    "- **Twitter Archieve**\n",
    "    - Timestamp columns are objects not dates\n",
    "    - Retweeted_status_id, reply to user id and replay to status id are flast not int\n",
    "    - There are rows have no dog images\n",
    "    - Dog stages not well filled and have misssed a lot of values, from the tidiness prespective we melt these stages in one   column and make it category type\n",
    "- **Image Predication** \n",
    "    - There are rows that were not predicted as dog\n",
    "    - Convert the melted P column to category type\n",
    "- **Tweets Count**\n",
    "    - Nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Efforts\n",
    "\n",
    "### Missing Data Fixing\n",
    "- Nothing to complete, no extra data needed after the gathering phase completeded\n",
    "- If it is doable, i would update the dog stages columns from a resonable sources\n",
    "\n",
    "### Removing invalid Data \n",
    "- I started to remove useless columns before the tidiness issues to reduce the redunancy and make it simple\n",
    "- Remove from twiter archive where retweeted_status_id is not NaN\n",
    "- Remove from twiter archive where in_reply_to_status_id is not NaN\n",
    "- Remove from twiter archive where expanded_urls is NaN\n",
    "- Remove from image prediection where the all dog predication are false\n",
    "- Remove columns (source, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id retweeted_status_user_id retweeted_status_timestamp)\n",
    "\n",
    "### Tidiness Fixing\n",
    "- Twitter archive data set\n",
    "    - Melt dog stages (to be one column)\n",
    "- Image predeiction data set\n",
    "    - Melt P columns to be one P which has the highest conf value and dog type is Ture\n",
    "        - Make addtional P column firstly that statify the above criteria, then remove all (P, Conf, is dog)\n",
    "- Merge twitter archieve with image prediction and tweets counta\n",
    "\n",
    "### Remaining Qulity Issues\n",
    "- Convert timestamp to datetime\n",
    "- Add addtional feilds from timestamp(day of week, hour)\n",
    "- Convert None values to NaN for all columns\n",
    "- Convert a or an as dog name to NaN\n",
    "- Convert dog breed to category\n",
    "\n",
    "### Another Master Data Set Options\n",
    "- This option is made as after completed this tidiy and clean data set has aeound 300-400 row which may be not enough for analysing, but i kept it as an more tidiy option after do the following extra steps:\n",
    "    - Remove rows that has inconsist rating, numerator less than 10 and denominator not equal to 10\n",
    "    - Melt dog stages in one column and convert it to category type\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
